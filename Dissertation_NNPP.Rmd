---
title: "Dissertation_NNPP"
output:
  html_document: default
  pdf_document: default
date: "2022-10-05"
---

```{r library, include = FALSE}
cat("\014")
rm(list = ls())

library(readr)
library(tidyverse)
library(ggplot2)
library(lme4)
library(emmeans)
library(ggpubr)
library(corrplot)
library(sjPlot)
library(lubridate)
library(likert)
library(tidylog)
library(data.table)
library(psych)
library(DataExplorer)
library(SmartEDA)  
library(tableone)
library(rmcorr)
library(DataExplorer)
```

```{r load datasets, include = FALSE}
raw_performance = read_csv("/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/performance.csv")

raw_word_utterance_count = read_csv("/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/wordUtteranceCountEveryone.csv")

raw_time = read_csv("/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/experiment_spreadsheet.csv")

raw_survey = read_csv("/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/SelfTalk_Winter2022_NNPP_October 9, 2022_10.45.csv") 
```

```{r data processing, include=FALSE}
# change characters to lower case, remove the spaces, and irrelevant strings in character strings, also create long dataset for performance_difference and private speech combination
processing_performance = raw_performance %>%
  mutate_if(is.character, tolower) %>% 
  mutate_if(is.character, gsub, pattern =" ", replace = "") %>%
  mutate_if(is.character, gsub, pattern ="-table1.csv", replace = "") %>% 
  mutate_if(is.character, gsub, pattern =".csv", replace = "") %>%
  mutate_if(is.character, gsub, pattern ="-", replace = "") %>%
  mutate(trial = readr::parse_number(L)) %>%
  mutate(L = gsub("[0-9]", "", L))
   
baseline = processing_performance %>% 
  filter(trial <= 2) %>%
  group_by(L) %>% 
  mutate(baseline_difference = mean(performance_difference, na.rm = T), 
         baseline_ratio = mean(performance_ratio, na.rm = T))

performance_baseline = left_join(
  processing_performance %>% filter(trial >=3), 
  baseline %>% select(L, baseline_ratio, baseline_difference) %>% distinct(), 
  by = "L")

processing_word_utterance_count = raw_word_utterance_count %>%
  mutate_if(is.character, tolower) %>% 
  mutate_if(is.character, gsub, pattern =" ", replace = "") %>% 
  mutate_if(is.character, gsub, pattern =".csv", replace = "") %>%
  mutate_if(is.character, gsub, pattern ="-", replace = "")

 
  word_count = pivot_longer(processing_word_utterance_count %>% select(L, wordCountTrial3, wordCountTrial4), cols = c("wordCountTrial3", "wordCountTrial4"), names_to ="trial", values_to = "word_count") %>%
    mutate(trial = dplyr::recode(trial, 
                                 "wordCountTrial3" = "3", 
                                 "wordCountTrial4" = "4") )

  utterance_count = pivot_longer(processing_word_utterance_count %>% select(L, utteranceCountTrial3, utteranceCountTrial4), cols = c("utteranceCountTrial3", "utteranceCountTrial4"), names_to ="trial", values_to = "utterance_count") %>%
    mutate(trial = dplyr::recode(trial, 
                                    "utteranceCountTrial3" = "3", 
                                    "utteranceCountTrial4" = "4"))

processing_word_utterance_long = full_join(word_count, utterance_count, by = c("L", "trial")) 

performance_baseline$trial = as.character(performance_baseline$trial)

number_60_division = function(x) as.numeric(x)/60 # creating a separate function to work under dplyr to transform time into seconds

processing_time = raw_time %>%
  select(Participant, Time1, Time2, Time3, Time4) %>%
  mutate_if(is.character, tolower) %>%
  mutate_if(is.character, gsub, pattern = " ", replace = "") %>%
  mutate_at(vars(-Participant), number_60_division) %>%
  pivot_longer(cols = c("Time1", "Time2", "Time3", "Time4"), names_to = "trial", values_to = "time") %>%
  mutate(trial = dplyr::recode(trial, "Time1" = "1", "Time2" = "2", "Time3" = "3", "Time4" = "4"))

performance_baseline_talk =  full_join(processing_word_utterance_long, performance_baseline, by = c("trial", "L"))

audio_yes_performance_difference_no = setdiff(processing_word_utterance_long$L, performance_baseline$L)
# character(0)

performance_yes_audio_no = setdiff(performance_baseline$L, processing_word_utterance_long$L)
# [1] "adelynnlefavebailey"  "alvinnguyen"          "ashlynsloane"         "bridgetmullings"      "britanygutierrezleon"
#  [6] "chloelin"             "cynthiaflores"        "deniznalankivrak"     "divyanshukawankar"    "gerardocortez"       
# [11] "gissellematus"        "hojeongkim"           "isabellaramos"        "jasonlee"             "joangreen"           
# [16] "julienguyen"          "kashikarathore"       "kaylaguzman"          "kaylasadaghiani"      "marcusvanderwatt"    
# [21] "maryramada"           "maxvroemen"           "natashakanhirun"      "nayelilopezrivera"    "nicholasfisher"      
# [26] "pawelvijayakumar"     "ricardoaltamirano"    "sharanaravindh"       "tatyanasimmonds"      "timothyliao"         
# [31] "timothyschneider"     "vanessacoronelzapata" "yeabsiraatnafu"       "yifanliu"             "yunjaehur"           
# [36] "zareenismail"         "zimuguan"  
processing_time$trial = as.numeric(processing_time$trial)
performance_baseline_talk$trial = as.numeric(performance_baseline_talk$trial)
names(performance_baseline_talk)[names(performance_baseline_talk)== "L"] = "Participant"


outlier_baseline = performance_baseline_talk %>% na.omit %>%
  select(Participant, baseline_ratio, baseline_difference) %>%
  distinct() %>%
  mutate(sd_baseline_difference = sd(baseline_difference, na.rm = T), 
         mean_baseline_difference = mean(baseline_difference, na.rm = T), 
         baseline_diff_min = mean_baseline_difference - 3*sd_baseline_difference, 
         baseline_diff_max = mean_baseline_difference + 3*sd_baseline_difference, 
         sd_baseline_ratio = sd(baseline_difference, na.rm = T), 
         mean_baseline_ratio = mean(baseline_ratio, na.rm = T), 
         baseline_ratio_min = mean_baseline_ratio - 3*sd_baseline_ratio, 
         baseline_ratio_max = mean_baseline_ratio + 3*sd_baseline_ratio) %>%
  filter(baseline_ratio > baseline_ratio_max | baseline_ratio < baseline_ratio_min | baseline_difference > baseline_diff_max | baseline_difference < baseline_diff_min) %>%
  select(Participant) %>%
  distinct()
# the baseline criteria excluded 1 participant, the ratio and the difference calculation resulted in the same outlier participant

outlier_performance = performance_baseline_talk %>% na.omit %>%
  mutate(sd_performance_difference = sd(performance_difference, na.rm = T), 
         mean_performance_difference = mean(performance_difference, na.rm = T), 
         performance_difference_min = mean_performance_difference - 3*sd_performance_difference, 
         performance_difference_max = mean_performance_difference + 3*sd_performance_difference, 
         sd_performance_ratio = sd(performance_ratio, na.rm = T), 
         mean_performance_ratio = mean(performance_ratio, na.rm = T), 
         performance_ratio_min = mean_performance_ratio - 3*sd_performance_ratio, 
         performance_ratio_max = mean_performance_ratio + 3*sd_performance_ratio) %>%
  filter(performance_difference > performance_difference_max | 
           performance_difference < performance_difference_min |
           performance_ratio > performance_ratio_max | 
           performance_ratio < performance_ratio_min) %>%
  select(Participant, trial)

#   The performance_difference exclusion criteria excluded 4 trials, the same trials and participants were excluded based on the performance_ratio criteria. 
#    Participant    trial
#   <chr>          <dbl>
# 1 elizabethlee       3
# 2 jeannienguyen      4
# 3 laradonabedian     3
# 4 shaolunwu          4

performance_baseline_talk= performance_baseline_talk %>%
  filter(!Participant %in% outlier_baseline) 

# the for loop below removes the outlier_performance_difference by excluding the pairs of (participant, trial) in the outlier_performance_difference dataset
for (i in 1:nrow(outlier_performance)) {
    performance_baseline_talk = performance_baseline_talk %>%
    filter(!(Participant == outlier_performance[i,] %>% pull(Participant) & trial == outlier_performance[i,] %>% pull(trial)))
}

performance_baseline_talk_time = full_join(performance_baseline_talk, processing_time %>% filter(trial >=3), by = c("Participant", "trial")) %>%
  mutate(word_min = word_count/time*60, 
         utterance_min = utterance_count/time*60)

process_survey = raw_survey %>%
  filter(!is.na(PID_name)) %>%
  mutate_at(vars(PID_name), tolower) %>%
  mutate_at(vars(PID_name), gsub, pattern = " ", replace = "") %>%
  mutate_at(vars(PID_name), gsub, pattern ="-", replace = "")


not_serious_id = process_survey %>%
  filter(TakeItSerious_Game_1 == "I did not follow the instructions of the game and instead tried to finish the game as quickly as possible.\n(1)" & TakeItSerious_Survey_1 == "I did not read those questions carefully, and instead, I answered them as quickly as possible.\n(1)") 

## one participant was excluded because they did not the take the game and the question seriously  
process_survey = process_survey %>%
  filter(!PID_name %in% not_serious_id) 

performance_yes_survey_no = setdiff(performance_baseline$L,process_survey$PID_name)
#  [1] "anacorrea"                "britanygutierrezleon"     "cesiaharorojas"           "deniznalankivrak"        
#  [5] "josephcasteldeoro"        "madelinesoares"           "mardinimardini"           "mckennaanello"           
#  [9] "nathanhoaita"             "nayelilopezrivera"        "nicholasfisher"           "sophianguyen"            
# [13] "stephanievaladezdiosdado" "timothyschneider"         "vanessacoronelzapata"     "xiangjie(fiona)liu"      
# [17] "yifanliu" 

process_survey$PID_name[which(grepl("zen", process_survey$PID_name))] = "zixuanzeng"
process_survey$PID_name[which(grepl("correa", process_survey$PID_name))] = "anacorrea"
process_survey$PID_name[which(grepl("rojas", process_survey$PID_name))] = "cesiaharorojas"
# cannot find chenlin
process_survey$PID_name[which(grepl("kivrak", process_survey$PID_name))] = "deniznalankivrak"
process_survey$PID_name[which(grepl("casteldeoro", process_survey$PID_name))] = "josephcasteldeoro"
process_survey$PID_name[which(grepl("soares", process_survey$PID_name))] = "madelinesoares"

process_survey$PID_name[which(grepl("mardini", process_survey$PID_name))] = "mardinimardini"

process_survey$PID_name[which(grepl("nathanta", process_survey$PID_name))] = "nathanhoaita"
# cannot find mckennaanello

process_survey$PID_name[which(grepl("fisher", process_survey$PID_name))] = "nicholasfisher"

process_survey$PID_name[which(grepl("stephanie", process_survey$PID_name))] = "stephanievaladezdiosdado"

process_survey$PID_name[which(grepl("xiangjie", process_survey$PID_name))] = "xiangjie(fiona)liu"

process_survey$PID_name[which(grepl("schneider", process_survey$PID_name))] = "timothyschneider"

process_survey$PID_name[which(grepl("yifan,liu", process_survey$PID_name))] = "yifanliu"

process_survey$PID_name[which(grepl("anello", process_survey$PID_name))] = "mckennaanello"

process_survey$PID_name[which(grepl("myname", process_survey$PID_name))] = "sophianguyen"
process_survey$PID_name[which(grepl("vanessam.coronelzapata", process_survey$PID_name))] = "vanessacoronelzapata"

process_survey$PID_name[which(grepl("nayeli", process_survey$PID_name))] = "nayelilopezrivera"
process_survey$PID_name[which(grepl("britany", process_survey$PID_name))] = "britanygutierrezleon"
performance_yes_survey_no= setdiff(performance_baseline$L,process_survey$PID_name)
# cannot find "chenlin"     
names(process_survey)[names(process_survey) == "PID_name"] = "Participant"

only_in_survey = setdiff(process_survey$Participant,performance_baseline$L )
#  [1] "pleasetypeyourfullname(first&last),andmakesureit'saccuratesincewe'llneedittomatchwiththegameresult.\n\n\ntheinformationinthisstudywillbeusedonlyforresearchpurposesandinwaysthatwillnotrevealwhoyouare.yournamewilllaterbereplacedbyarandomlygeneratedidduringthedataanalysisofthestudy"
#  [2] "{\"importid\":\"qid3_text\"}"                                                                                                                                                                                                                                                           
#  [3] "jennifercastaneda"                                                                                                                                                                                                                                                                      
#  [4] "weijouhuang"                                                                                                                                                                                                                                                                            
#  [5] "honganhnguyen"                                                                                                                                                                                                                                                                          
#  [6] "diannalopez"                                                                                                                                                                                                                                                                            
#  [7] "yasminelopez"                                                                                                                                                                                                                                                                           
#  [8] "benjaminhadler"                                                                                                                                                                                                                                                                         
#  [9] "natalievarelamares"                                                                                                                                                                                                                                                                     
# [10] "victoriamoralesvargas"                                                                                                                                                                                                                                                                  
# [11] "ershuanglu"                                                                                                                                                                                                                                                                             
# [12] "tianlijiang"                                                                                                                                                                                                                                                                            
# [13] "jessicaju" 

survey_for_combine = process_survey %>% 
  select(TakeItSerious_Game_1:Participant)

# From qualitative feedback "I think the study was actually very fun and it helped me learn a new way to recall memories using my hand placements."  "It was a very interesting study and I got a chance to learn a good strategy for memorizing." 

final_participants = performance_baseline_talk %>%
  filter(!Participant %in% not_serious_id) %>%
  na.omit %>% 
  pull(Participant)

sample_size = length(unique(final_participants)) # 118

```

```{r word vs utterance, include=FALSE}
# thinking about how to connect word with utterance
subjective_1 = process_survey %>%
  select(Participant, PS_Lkrt_rati_1_1:language_PS1) %>%
  mutate(trial = 3)

names(subjective_1) = c("Participant", "PS_Lkrt_rati", "PS_Lkt_conf", "PS_pcg_rati", "PS_talk_pcg_conf", "comfortable_PS", "Content_naming", "Content_prasing", "Content_criticize", "language", "trial")

subjective_2 = process_survey %>%
  select(Participant, PS_Lkrt_rati_2_1:language_PS2) %>%
  mutate(trial = 4)

names(subjective_2) = c("Participant", "PS_Lkrt_rati", "PS_Lkt_conf", "PS_pcg_rati", "PS_talk_pcg_conf", "comfortable_PS", "Content_naming", "Content_prasing", "Content_criticize", "language", "trial")

subjective = rbind(subjective_1, subjective_2)

performance_baseline_talk_time_survey = left_join(performance_baseline_talk_time, survey_for_combine, by = "Participant") %>%
  left_join(subjective, by = c("Participant", "trial")) %>%
  filter(Participant %in% final_participants) 

write_csv(performance_baseline_talk_time_survey, "/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/NNPP_cleaned_compiled.csv")

recoded_full_df = performance_baseline_talk_time_survey %>%
  mutate_at(vars(TakeItSerious_Game_1, TakeItSerious_Survey_1, SSS_family, SSS_self),
            ~dplyr::recode(.,
                    "I did not follow the instructions of the game and instead tried to finish the game as quickly as possible.\n1" = "1", 
                    "I followed the instructions of the game, and played the game to the best of my ability\n4" = "4", 
                    "I did not read those questions carefully, and instead, I answered them as quickly as possible.\n1" ="1", 
                    "I read the questions carefully, and answered honestly to the best of my ability\n4" = "4",
                    "1 (the worst off)"= "1",
                    "10 (the best off)" = "10", )) %>%
  mutate_at(vars(PS_Lkrt_rati, PS_Lkt_conf, PS_pcg_rati, PS_pcg_rati, Age, TakeItSerious_Game_1, TakeItSerious_Survey_1, PS_talk_pcg_conf,	comfortable_PS, Content_naming, Content_prasing, Content_criticize, SSS_self, SSS_family), 
            ~ as.numeric(.))

write_csv(recoded_full_df, "/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/recoded_full_df.csv")
```

```{r corrplot function and corrplot, echo=FALSE}

cor.test(recoded_full_df %>% pull(word_min), recoded_full_df %>% pull(PS_Lkrt_rati))
#  	Pearson's product-moment correlation
# 
# data:  recoded_full_df %>% pull(word_min) and recoded_full_df %>% pull(PS_Lkrt_rati)
# t = 5.4251, df = 229, p-value = 1.47e-07
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.2178837 0.4470736
# sample estimates:
#       cor 
# 0.3374704 


cor.test(recoded_full_df %>% pull(word_min), recoded_full_df %>% pull(PS_pcg_rati))
# 	Pearson's product-moment correlation
# 
# data:  recoded_full_df %>% pull(word_min) and recoded_full_df %>% pull(PS_pcg_rati)
# t = 5.8588, df = 229, p-value = 1.61e-08
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.2433085 0.4683006
# sample estimates:
#       cor 
# 0.3610472 

cor.test(recoded_full_df %>% pull(utterance_min), recoded_full_df %>% pull(PS_Lkrt_rati))
# 	Pearson's product-moment correlation
# 
# data:  recoded_full_df %>% pull(utterance_min) and recoded_full_df %>% pull(PS_Lkrt_rati)
# t = 6.7518, df = 229, p-value = 1.188e-10
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.2938318 0.5097253
# sample estimates:
#       cor 
# 0.4074558  

cor.test(recoded_full_df %>% pull(utterance_min), recoded_full_df %>% pull(PS_pcg_rati))
# 	Pearson's product-moment correlation
# 
# data:  recoded_full_df %>% pull(utterance_min) and recoded_full_df %>% pull(PS_pcg_rati)
# t = 6.4597, df = 229, p-value = 6.223e-10
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.2775846 0.4965123
# sample estimates:
#       cor 
# 0.3925955 


cor.test(recoded_full_df %>% pull(utterance_count), recoded_full_df %>% pull(PS_pcg_rati))
# 	Pearson's product-moment correlation
# 
# data:  recoded_full_df %>% pull(utterance_count) and recoded_full_df %>% pull(PS_pcg_rati)
# t = 7.0711, df = 233, p-value = 1.777e-11
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.3089828 0.5203185
# sample estimates:
#       cor 
# 0.4203347  
cor.test(recoded_full_df %>% pull(word_count), recoded_full_df %>% pull(PS_pcg_rati))
# 	Pearson's product-moment correlation
# 
# data:  recoded_full_df %>% pull(word_count) and recoded_full_df %>% pull(PS_pcg_rati)
# t = 4.7345, df = 233, p-value = 3.814e-06
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.1749025 0.4087215
# sample estimates:
#       cor 
# 0.2962441

correlation_zeroOrder_plot = function(df, original_col_list, renamed_col_list) {
    # corr.matrix -- correlation table and heatmap
    corelation_matrix = as.data.frame(df[, original_col_list])

    # corelation_matrix[is.na(corelation_matrix)] <- 0
    colnames(corelation_matrix) = renamed_col_list

    corelation_matrix_cor <- round(cor(corelation_matrix, use = "pairwise.complete.obs"),
        3)
    res1 <- cor.mtest(corelation_matrix_cor, conf.level = 0.95)

    corrplot(corelation_matrix_cor, p.mat = res1$p, method = "color", type = "upper",
        sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.9, tl.cex = 0.9,
        insig = "label_sig", pch.col = "white")

    # corelation_matrix_plot =
    # corrplot::corrplot.mixed(corelation_matrix_cor,lower.col =
    # 'black', number.cex = .7,p.mat = res1$p, upper = 'color',
    # sig.level = c(.001, .01, .05), pch.cex = .9, tl.cex = 0.5,
    # insig = 'label_sig', pch.col = 'white')
}

names(recoded_full_df)
#  [1] "Participant"                  "trial"                       
#  [3] "word_count"                   "utterance_count"             
#  [5] "performance_difference" "baseline"                   
#  [7] "time"                         "word_min"                    
#  [9] "utterance_min"                "TakeItSerious_Game_1"        
# [11] "TakeItSerious_Survey_1"       "Age"                         
# [13] "Gender"                       "Gender_3_TEXT"               
# [15] "EthnoRacial"                  "ETHNORACIAL_mixed"           
# [17] "Country_born"                 "Country_growUp"              
# [19] "AgeToUS"                      "COLLEGE STANDING"            
# [21] "TRANSFER STUDENT"             "SSS_self"                    
# [23] "SSS_family"                   "PS_Lkrt_rati"                
# [25] "PS_Lkt_conf"                  "PS_pcg_rati"                 
# [27] "PS_talk_pcg_conf"             "comfortable_PS"              
# [29] "Content_naming"               "Content_prasing"             
# [31] "Content_criticize"            "language"   

correlation_zeroOrder_plot(
  df = recoded_full_df, 
  original_col_list = c("word_count", "word_min", "utterance_count", "utterance_min", "performance_difference", "performance_ratio",  "baseline_difference", "baseline_ratio", "time", "PS_Lkrt_rati", "PS_Lkt_conf", "PS_pcg_rati", "PS_talk_pcg_conf", "comfortable_PS"), 
  renamed_col_list = c("word_count", "word_min", "utterance_count", "utterance_min", "performance_difference", "performance_ratio", "baseline_difference", "baseline_ratio", "time",  "PS_Lkrt_rati", "PS_Lkt_conf", "PS_pcg_rati", "PS_talk_pcg_conf", "comfortable")) ## there is no correlation between performance_difference and the extent to which they talk out loud during the game. 
```

```{r SURVEY clean data and recode, echo=FALSE}

Likert_scale_viz = function(df, original_col, renamed_col, input_level){
  df[[original_col]] = factor(df[[original_col]], levels = input_level, ordered = TRUE)
  names(df)[names(df) == original_col] = renamed_col
result = data.frame(df[,which(colnames(df) == renamed_col)]) 
 names(result)= gsub("\\."," ", names(result))
  plot(likert(result), legend.position = "right")
}


original_col = c("TakeItSerious_Survey_1")
renamed_col = c("How seriously did you answer the questions after the games")
df = recoded_full_df
input_level = c("1", "2", "3", "4" )

Likert_scale_plot = (Likert_scale_viz(df, original_col, renamed_col, input_level))

### verbal content questions
recoded_full_df$Content_prasing = as.character(recoded_full_df$Content_prasing)
recoded_full_df$Content_criticize = as.character(recoded_full_df$Content_criticize)
recoded_full_df$Content_naming = as.character(recoded_full_df$Content_naming)
verbal_content  <- recoded_full_df  %>% 
  select(Content_naming, Content_prasing, Content_criticize) %>%
  rename("Naming the object that you saw" = Content_naming,
          "Saying positive things to yourself (e.g. praising yourself)" = Content_prasing,
          "Saying negative things to yourself (e.g. criticizing yourself)" = Content_criticize) %>%
  mutate_if(is.character, function(x){factor(x, levels =c("1", "2", "3", "4", "5","6", "7"))}) 

verbal_content = data.frame(verbal_content)
 names(verbal_content)= gsub("\\."," ", names(verbal_content))

## Not Grouped
# plot(likert(dh)) # basic not grouped
Likert_scale_multipleQs = (plot(likert(verbal_content), legend.position="right"))

### density plots
# PS_pcg_rati 1 & 2
density_pcg = (ggplot(data = recoded_full_df, aes(x = PS_pcg_rati)) + geom_density() +
  geom_vline(aes(xintercept = median(recoded_full_df$PS_pcg_rati, na.rm = T)), 
             linetype = "dashed", size = 0.6, color = "#d8b365") +labs(title = "Density and median of private speech percentage rating", x = "what percentage of the time were you talking out loud to yourself \n(as opposed to being silent inside your head)") + theme_classic())
```

```{r SURVEY summary might delete later, echo=FALSE}
describe(recoded_full_df) # but it also has categorical data
```

```{r EDA, include=FALSE}

tableOne <- CreateTableOne(vars = colnames(recoded_full_df %>% select(word_count, utterance_count, baseline_difference, performance_difference, time, word_min, utterance_min, TakeItSerious_Game_1, TakeItSerious_Survey_1, PS_Lkrt_rati, PS_Lkt_conf, PS_pcg_rati, PS_talk_pcg_conf, comfortable_PS, Content_naming, Content_prasing, Content_criticize)), 
                           strata = c("Gender"), 
                           data = recoded_full_df %>% filter(!Gender == "Non-binary"))
  #                                         Stratified by Gender
  #                                          Man           Women         p      test
  # n                                           54           158                    
  # word_count (mean (SD))                   62.81 (47.04) 58.34 (41.72)  0.513     
  # utterance_count (mean (SD))              30.56 (10.63) 27.90 (12.36)  0.160     
  # baseline (mean (SD))                     6.35 (2.65)   5.44 (2.94)   0.044     
  # performance_difference (mean (SD))  5.89 (3.98)   5.90 (3.68)   0.982     
  # time (mean (SD))                         62.56 (18.31) 70.88 (29.65)  0.054     
  # word_min (mean (SD))                     57.88 (31.50) 52.96 (37.10)  0.386     
  # utterance_min (mean (SD))                30.70 (11.59) 25.87 (11.32)  0.008     
  # TakeItSerious_Game_1 (mean (SD))          3.85 (0.36)   3.82 (0.44)   0.664     
  # TakeItSerious_Survey_1 (mean (SD))        3.96 (0.19)   3.96 (0.19)   0.975     
  # PS_Lkrt_rati (mean (SD))                  5.59 (1.12)   5.32 (1.36)   0.190     
  # PS_Lkt_conf (mean (SD))                   6.33 (0.97)   6.18 (1.02)   0.327     
  # PS_pcg_rati (mean (SD))                  76.63 (19.08) 75.18 (22.69)  0.674     
  # PS_talk_pcg_conf (mean (SD))              6.07 (1.04)   6.05 (0.94)   0.878     
  # comfortable_PS (mean (SD))                5.50 (1.60)   4.74 (1.76)   0.006     
  # Content_naming (mean (SD))                6.46 (1.06)   6.11 (1.38)   0.088     
  # Content_prasing (mean (SD))               1.77 (1.10)   2.56 (1.86)   0.028     
  # Content_criticize (mean (SD))             2.00 (1.51)   2.03 (1.26)   0.916

print(
  tableOne,
  nonnormal = c("word_count","word_min", "utterance_count", "baseline_difference", "time", "performance_difference"),
  showAllLevels = TRUE)
# 
# setwd("/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data")
# recoded_full_df %>%
#     create_report(
#         output_file = "EFA_NNPP_Report"
#     )
```

```{r scaling data, include=FALSE}
scaled_df = recoded_full_df %>%
  mutate_at(vars(Content_naming,Content_prasing, Content_criticize), as.numeric) %>%
  select(word_count: utterance_min, PS_Lkrt_rati: Content_criticize) %>%
  scale() %>%
  data.frame()

scaled_full_df = cbind(recoded_full_df %>%
  select(Participant, trial, TakeItSerious_Game_1:SSS_family, language), scaled_df) 
```

```{r analysis, echo=FALSE}

full_model_word_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio * word_count + (1|Participant))
lesion_model_word_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio + word_count + (1|Participant))

tab_model(full_model_word_ratio,lesion_model_word_ratio, p.val = "kr" )

full_model_word_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference * word_count + (1|Participant))
lesion_model_word_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + word_count + (1|Participant))

tab_model(full_model_word_diff,lesion_model_word_diff, p.val = "kr" )

plot_model(full_model_word_ratio, type = "pred", terms = c("word_count", "baseline_ratio"))
plot_model(full_model_word_diff, type = "pred", terms = c("word_count", "baseline_difference"))

# Data: performance_difference_baseline_talk_time_survey
# Models:
# lesion_model_word: performance_difference ~ baseline + word_count + (1 | Participant)
# full_model_word: performance_difference ~ baseline * word_count + (1 | Participant)
#                   npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
# lesion_model_word    5 1242.0 1259.3 -616.02   1232.0                     
# full_model_word      6 1243.7 1264.4 -615.84   1231.7 0.3517  1     0.5531

full_model_utterance_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference * utterance_count + (1|Participant))
lesion_model_utterance_diff = lmer(data = scaled_full_df, performance_difference   ~ baseline_difference + utterance_count + (1|Participant))
tab_model(full_model_utterance_diff,lesion_model_utterance_diff, p.val = "kr" )
plot_model(full_model_utterance_diff, type = "pred", terms = c("utterance_count", "baseline_difference"))

# Data: scaled_full_df
# Models:
# lesion_model_utterance: performance_difference ~ baseline + utterance_count + (1 | Participant)
# full_model_utterance: performance_difference ~ baseline * utterance_count + (1 | Participant)
#                        npar    AIC    BIC  logLik deviance Chisq Df Pr(>Chisq)
# lesion_model_utterance    5 1244.2 1261.4 -617.08   1234.2                    
# full_model_utterance      6 1246.2 1266.9 -617.08   1234.2 0.008  1     0.9286

plot_model(full_model_utterance_diff, type = "pred", terms = c("utterance_count", "baseline_difference"))


m1_utterance_min_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference * utterance_min + (1|Participant))
m0_utterance_min_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + utterance_min + (1|Participant))

tab_model(m1_utterance_min_diff,m0_utterance_min_diff, p.val = "kr" )
plot_model(m1_utterance_min_diff, type = "pred", terms = c("utterance_min", "baseline_difference"))

full_model_word_min_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference * word_min + (1|Participant))
lesion_word_min_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + word_min + (1|Participant))

tab_model(full_model_word_min_diff,lesion_word_min_diff, p.val = "kr" )

plot_model(full_model_word_min_diff, type = "pred", terms = c("word_min", "baseline_difference"))
##
full_model_word_min_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio * word_min + (1|Participant))
lesion_word_min_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio + word_min + (1|Participant))

tab_model(full_model_word_min_ratio,lesion_word_min_ratio, p.val = "kr" )

plot_model(full_model_word_min_diff, type = "pred", terms = c("word_min", "baseline_difference"))

full_model_utterance_min_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio * utterance_min + (1|Participant))
lesion_utterance_min_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio+ utterance_min + (1|Participant))

tab_model(full_model_utterance_min_ratio, lesion_utterance_min_ratio, p.val = "kr" )
full_model_word_min_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio * word_min + (1|Participant))
lesion_model_word_min_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio + word_min + (1|Participant))

tab_model(full_model_word_min_ratio,lesion_model_word_min_ratio,  p.val = "kr" )

### looking at main effect 
no_word_min = lmer(data = scaled_full_df %>% filter(!is.na(word_min)), performance_difference ~ baseline_difference + (1|Participant))
lesion_word_min = lmer(data = scaled_full_df %>% filter(!is.na(word_min)), performance_difference ~ baseline_difference + word_min + (1|Participant))
tab_model(no_word_min, lesion_word_min, p.val = "kr")
plot_model(lesion_word_min, type = "pred", terms = c("word_min"))


no_utterance_min = lmer(data = scaled_full_df %>% filter(!is.na(utterance_min)), performance_difference ~ baseline_difference + (1|Participant))
lesion_utterance_min = lmer(data = scaled_full_df %>% filter(!is.na(utterance_min)), performance_difference ~ baseline_difference + utterance_min + (1|Participant))
tab_model(no_utterance_min, lesion_utterance_min, p.val = "kr")
plot_model(lesion_utterance_min, type = "pred", terms = c("utterance_min"))


no_word = lmer(data = scaled_full_df %>% filter(!is.na(word_count)), performance_difference ~ baseline_difference + (1|Participant))
lesion_word = lmer(data = scaled_full_df %>% filter(!is.na(word_count)), performance_difference ~ baseline_difference + word_count + (1|Participant))
tab_model(no_word, lesion_word, p.val = "kr")

no_utterance = lmer(data = scaled_full_df %>% filter(!is.na(utterance_count)), performance_difference ~ baseline_difference + (1|Participant))
lesion_utterance = lmer(data = scaled_full_df %>% filter(!is.na(utterance_count)), performance_difference ~ baseline_difference + utterance_count + (1|Participant))

tab_model(no_utterance, lesion_utterance, p.val = "kr")
```

```{r comfortableness, echo=FALSE}
no_comfortableness = lmer(data = scaled_full_df %>% filter(!is.na(comfortable_PS)), performance_difference ~ baseline_difference + (1|Participant))
comfortableness = lmer(data = scaled_full_df %>% filter(!is.na(comfortable_PS)), performance_difference ~ baseline_difference + comfortable_PS + (1|Participant))
comfortableness_interaction = lmer(data = scaled_full_df %>% filter(!is.na(comfortable_PS)), performance_difference ~ baseline_difference * comfortable_PS + (1|Participant))

tab_model(comfortableness, comfortableness_interaction, p.val = "kr")
plot_model(comfortableness, type = "pred")


utter_rate_comfort = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + utterance_min +comfortable_PS + (1|Participant))
tab_model( utter_rate_comfort, p.val = "kr")

word_rate_comfort = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + word_min +comfortable_PS + (1|Participant))
tab_model( word_rate_comfort, p.val = "kr")
```

```{r subjective, include=FALSE}
## adding comfortableness
no_likert = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + (1|Participant))

lesion_likert = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_Lkrt_rati + (1|Participant))

interaction_likert = lmer(data = scaled_full_df, performance_difference ~ baseline_difference * PS_Lkrt_rati + (1|Participant))
tab_model(interaction_likert, lesion_likert, p.val = "kr")
tab_model(lesion_likert, p.val = "kr")

subjective_against_comfort = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_Lkrt_rati + comfortable_PS + (1|Participant))
tab_model(subjective_against_comfort, p.val = "kr")



baseline_likert_plus = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_Lkrt_rati + (1|Participant))

baseline_likert_comfort_plus = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_Lkrt_rati + comfortable_PS+ (1|Participant))


tab_model(no_likert, lesion_likert, p.val = "kr")
tab_model(lesion_likert, interaction_likert, p.val = "kr")
tab_model(baseline_likert_plus, baseline_likert_comfort_plus, p.val = "kr")

### adding for percentage
## adding comfortableness
no_pcg = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + (1|Participant))
lesion_pcg = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_pcg_rati + (1|Participant))
interaction_pcg = lmer(data = scaled_full_df, performance_difference ~ baseline_difference * PS_pcg_rati + (1|Participant))
baseline_pcg_plus = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_pcg_rati + (1|Participant))
baseline_pcg_comfort_plus = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_pcg_rati + comfortable_PS+ (1|Participant))

tab_model(no_pcg, lesion_pcg, p.val = "kr")
tab_model(lesion_pcg, interaction_pcg, p.val = "kr")
tab_model(baseline_pcg_plus, baseline_pcg_comfort_plus, p.val = "kr")


```

```{r subjective and objective, include=FALSE}
m1 = lmer(data = scaled_full_df, PS_Lkrt_rati ~ utterance_min + word_min + utterance_count + word_count + (1|Participant))
m2 = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_pcg_rati + comfortable_PS+ (1|Participant))

```

```{r baseline and self talk, include=FALSE}
# are baseline and self talk related - utterance
m1 = lmer(data = scaled_full_df %>% filter(!is.na(utterance_count), !is.na(time)), baseline_difference ~ time + utterance_count + (1|Participant))

m0 = lmer(data = scaled_full_df %>% filter(!is.na(utterance_count), !is.na(time)), baseline_difference ~ time + (1|Participant))

anova(m1,m0)

# are baseline and self talk related - word
m1 = lmer(data = scaled_full_df %>% filter(!is.na(word_count), !is.na(time)), baseline_difference ~ time + word_count + (1|Participant))

m0 = lmer(data = scaled_full_df %>% filter(!is.na(word_count), !is.na(time)), baseline_difference ~ time + (1|Participant))

anova(m1,m0)

summary(lm(data = scaled_full_df, baseline_difference ~ time + word_count))
```

```{r determining ration versus difference, include=FALSE}
# voting for ratio rather than difference because there seems to be a disadvantage for participants whose turns assuming perfect is high - more cognitive load
## according to the analyses below there is no correlation between the error they are getting and the turns they need to get 

rmcorr(
  participant = L,
  measure1 = performance_difference,
  measure2 = turn_assume_perfect,
  processing_performance,
  CI.level = 0.95,
  CIs = c("analytic", "bootstrap"),
  nreps = 100,
  bstrap.out = F
)
# Repeated measures correlation
# 
# r
# 0.01058324
# 
# degrees of freedom
# 465
# 
# p-value
# 0.8195691
# 
# 95% confidence interval
# -0.08042805 0.1014195 


rmcorr(
  participant = L,
  measure1 = performance_ratio,
  measure2 = turn_assume_perfect,
  dataset = processing_performance,
  CI.level = 0.95,
  CIs = c("analytic", "bootstrap"),
  nreps = 100,
  bstrap.out = F
)
# Repeated measures correlation
# 
# r
# -0.06591199
# 
# degrees of freedom
# 465
# 
# p-value
# 0.1549973
# 
# 95% confidence interval
# -0.1559114 0.02517277 
```
