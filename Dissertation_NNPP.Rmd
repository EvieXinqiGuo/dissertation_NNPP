---
title: "Dissertation_NNPP"
output:
  html_document: default
  pdf_document: default
date: "2022-10-05"
---

```{r library, include = FALSE}
cat("\014")
rm(list = ls())

library(readr)
library(tidyverse)
library(ggplot2)
library(lme4)
library(emmeans)
library(ggpubr)
library(corrplot)
library(sjPlot)
library(lubridate)
library(likert)
library(tidylog)
library(data.table)
library(psych)
library(DataExplorer)
library(SmartEDA)  
library(tableone)
library(rmcorr)
library(DataExplorer)
```

```{r load datasets, include = FALSE}
raw_performance = read_csv("/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/performance.csv")

raw_word_utterance_count = read_csv("/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/wordUtteranceCountEveryone.csv")

raw_time = read_csv("/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/experiment_spreadsheet.csv")

raw_survey = read_csv("/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/SelfTalk_Winter2022_NNPP_October 9, 2022_10.45.csv") 

raw_content_count = read_csv("/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/content_everyone.csv") 
```

```{r data processing, include=FALSE}
# change characters to lower case, remove the spaces, and irrelevant strings in character strings, also create long data set for performance_difference and private speech combination
processing_performance = raw_performance %>%
  mutate_if(is.character, tolower) %>% 
  mutate_if(is.character, gsub, pattern =" ", replace = "") %>%
  mutate_if(is.character, gsub, pattern ="-table1.csv", replace = "") %>% 
  mutate_if(is.character, gsub, pattern =".csv", replace = "") %>%
  mutate_if(is.character, gsub, pattern ="-", replace = "") %>%
  mutate(trial = readr::parse_number(L)) %>%
  mutate(L = gsub("[0-9]", "", L))

baseline = processing_performance %>% 
  filter(trial <= 2) %>%
  group_by(L) %>% 
  dplyr::summarise(baseline_difference = mean(performance_difference, na.rm = T), 
         baseline_ratio = mean(performance_ratio, na.rm = T)) 

performance_baseline = left_join(
  processing_performance %>% filter(trial >=3), 
  baseline %>% select(L, baseline_ratio, baseline_difference) %>% distinct(), 
  by = "L")

processing_word_utterance_count = raw_word_utterance_count %>%
  mutate_if(is.character, tolower) %>% 
  mutate_if(is.character, gsub, pattern =" ", replace = "") %>% 
  mutate_if(is.character, gsub, pattern =".csv", replace = "") %>%
  mutate_if(is.character, gsub, pattern ="-", replace = "")

 
  word_count = pivot_longer(processing_word_utterance_count %>% select(L, wordCountTrial3, wordCountTrial4), cols = c("wordCountTrial3", "wordCountTrial4"), names_to ="trial", values_to = "word_count") %>%
    mutate(trial = dplyr::recode(trial, 
                                 "wordCountTrial3" = "3", 
                                 "wordCountTrial4" = "4") )

  utterance_count = pivot_longer(processing_word_utterance_count %>% select(L, utteranceCountTrial3, utteranceCountTrial4), cols = c("utteranceCountTrial3", "utteranceCountTrial4"), names_to ="trial", values_to = "utterance_count") %>%
    mutate(trial = dplyr::recode(trial, 
                                    "utteranceCountTrial3" = "3", 
                                    "utteranceCountTrial4" = "4"))

processing_content_count = raw_content_count %>%
  mutate_if(is.character, tolower) %>% 
  mutate_if(is.character, gsub, pattern =" ", replace = "") %>% 
  mutate_if(is.character, gsub, pattern =".csv", replace = "") %>%
  mutate_if(is.character, gsub, pattern ="-", replace = "")  

processing_content_count_wide = processing_content_count %>%
  pivot_wider(
    names_from = content_type,
    values_from =count, 
    values_fill = 0)

processing_word_utterance_long = full_join(word_count, utterance_count, by = c("L", "trial")) 

performance_baseline$trial = as.character(performance_baseline$trial)

number_60_division = function(x) as.numeric(x)/60 # creating a separate function to work under dplyr to transform time into seconds

processing_time = raw_time %>%
  select(Participant, Time1, Time2, Time3, Time4) %>%
  mutate_if(is.character, tolower) %>%
  mutate_if(is.character, gsub, pattern = " ", replace = "") %>%
  mutate_at(vars(-Participant), number_60_division) %>%
  pivot_longer(cols = c("Time1", "Time2", "Time3", "Time4"), names_to = "trial", values_to = "time") %>%
  mutate(trial = dplyr::recode(trial, "Time1" = "1", "Time2" = "2", "Time3" = "3", "Time4" = "4"))

performance_baseline_talk =  full_join(processing_word_utterance_long, performance_baseline, by = c("trial", "L"))


audio_yes_performance_difference_no = setdiff(processing_word_utterance_long$L, performance_baseline$L)
# character(0)

performance_yes_audio_no = setdiff(performance_baseline$L, processing_word_utterance_long$L)
# [1] "adelynnlefavebailey"  "alvinnguyen"          "ashlynsloane"         "bridgetmullings"      "britanygutierrezleon"
#  [6] "chloelin"             "cynthiaflores"        "deniznalankivrak"     "divyanshukawankar"    "gerardocortez"       
# [11] "gissellematus"        "hojeongkim"           "isabellaramos"        "jasonlee"             "joangreen"           
# [16] "julienguyen"          "kashikarathore"       "kaylaguzman"          "kaylasadaghiani"      "marcusvanderwatt"    
# [21] "maryramada"           "maxvroemen"           "natashakanhirun"      "nayelilopezrivera"    "nicholasfisher"      
# [26] "pawelvijayakumar"     "ricardoaltamirano"    "sharanaravindh"       "tatyanasimmonds"      "timothyliao"         
# [31] "timothyschneider"     "vanessacoronelzapata" "yeabsiraatnafu"       "yifanliu"             "yunjaehur"           
# [36] "zareenismail"         "zimuguan"  
processing_time$trial = as.numeric(processing_time$trial)
performance_baseline_talk$trial = as.numeric(performance_baseline_talk$trial)
names(performance_baseline_talk)[names(performance_baseline_talk)== "L"] = "Participant"

performance_yes_content_no = setdiff(performance_baseline_talk$Participant, processing_content_count_wide$Participant)
performance_no_content_yes = setdiff(processing_content_count_wide$Participant,performance_baseline_talk$Participant)

performance_baseline_talk =  left_join(performance_baseline_talk, processing_content_count_wide, by = c("trial", "Participant"))

outlier_baseline = performance_baseline_talk %>% na.omit %>%
  select(Participant, baseline_ratio, baseline_difference) %>%
  distinct() %>%
  mutate(sd_baseline_difference = sd(baseline_difference, na.rm = T), 
         mean_baseline_difference = mean(baseline_difference, na.rm = T), 
         baseline_diff_min = mean_baseline_difference - 3*sd_baseline_difference, 
         baseline_diff_max = mean_baseline_difference + 3*sd_baseline_difference, 
         sd_baseline_ratio = sd(baseline_difference, na.rm = T), 
         mean_baseline_ratio = mean(baseline_ratio, na.rm = T), 
         baseline_ratio_min = mean_baseline_ratio - 3*sd_baseline_ratio, 
         baseline_ratio_max = mean_baseline_ratio + 3*sd_baseline_ratio) %>%
  filter(baseline_ratio > baseline_ratio_max | baseline_ratio < baseline_ratio_min | baseline_difference > baseline_diff_max | baseline_difference < baseline_diff_min) %>%
  select(Participant) %>%
  distinct()
# the baseline criteria excluded 1 participant, the ratio and the difference calculation resulted in the same outlier participant

outlier_performance = performance_baseline_talk %>% na.omit %>%
  mutate(sd_performance_difference = sd(performance_difference, na.rm = T), 
         mean_performance_difference = mean(performance_difference, na.rm = T), 
         performance_difference_min = mean_performance_difference - 3*sd_performance_difference, 
         performance_difference_max = mean_performance_difference + 3*sd_performance_difference, 
         sd_performance_ratio = sd(performance_ratio, na.rm = T), 
         mean_performance_ratio = mean(performance_ratio, na.rm = T), 
         performance_ratio_min = mean_performance_ratio - 3*sd_performance_ratio, 
         performance_ratio_max = mean_performance_ratio + 3*sd_performance_ratio) %>%
  filter(performance_difference > performance_difference_max | 
           performance_difference < performance_difference_min |
           performance_ratio > performance_ratio_max | 
           performance_ratio < performance_ratio_min) %>%
  select(Participant, trial)

#   The performance_difference exclusion criteria excluded 4 trials, the same trials and participants were excluded based on the performance_ratio criteria. 
#    Participant    trial
#   <chr>          <dbl>
# 1 elizabethlee       3
# 2 jeannienguyen      4
# 3 laradonabedian     3
# 4 shaolunwu          4

performance_baseline_talk= performance_baseline_talk %>%
  filter(!Participant %in% outlier_baseline) 

# the for loop below removes the outlier_performance_difference by excluding the pairs of (participant, trial) in the outlier_performance_difference dataset
for (i in 1:nrow(outlier_performance)) {
    performance_baseline_talk = performance_baseline_talk %>%
    filter(!(Participant == outlier_performance[i,] %>% pull(Participant) & trial == outlier_performance[i,] %>% pull(trial)))
}

performance_baseline_talk_time = full_join(performance_baseline_talk, processing_time %>% filter(trial >=3), by = c("Participant", "trial")) %>%
  mutate(word_min = word_count/time*60, 
         utterance_min = utterance_count/time*60)

process_survey = raw_survey %>%
  filter(!is.na(PID_name)) %>%
  mutate_at(vars(PID_name), tolower) %>%
  mutate_at(vars(PID_name), gsub, pattern = " ", replace = "") %>%
  mutate_at(vars(PID_name), gsub, pattern ="-", replace = "")


not_serious_id = process_survey %>%
  filter(TakeItSerious_Game_1 == "I did not follow the instructions of the game and instead tried to finish the game as quickly as possible.\n(1)" & TakeItSerious_Survey_1 == "I did not read those questions carefully, and instead, I answered them as quickly as possible.\n(1)") 

## one participant was excluded because they did not the take the game and the question seriously  
process_survey = process_survey %>%
  filter(!PID_name %in% not_serious_id) 

performance_yes_survey_no = setdiff(performance_baseline$L,process_survey$PID_name)
#  [1] "anacorrea"                "britanygutierrezleon"     "cesiaharorojas"           "deniznalankivrak"        
#  [5] "josephcasteldeoro"        "madelinesoares"           "mardinimardini"           "mckennaanello"           
#  [9] "nathanhoaita"             "nayelilopezrivera"        "nicholasfisher"           "sophianguyen"            
# [13] "stephanievaladezdiosdado" "timothyschneider"         "vanessacoronelzapata"     "xiangjie(fiona)liu"      
# [17] "yifanliu" 

process_survey$PID_name[which(grepl("zen", process_survey$PID_name))] = "zixuanzeng"
process_survey$PID_name[which(grepl("correa", process_survey$PID_name))] = "anacorrea"
process_survey$PID_name[which(grepl("rojas", process_survey$PID_name))] = "cesiaharorojas"
# cannot find chenlin
process_survey$PID_name[which(grepl("kivrak", process_survey$PID_name))] = "deniznalankivrak"
process_survey$PID_name[which(grepl("casteldeoro", process_survey$PID_name))] = "josephcasteldeoro"
process_survey$PID_name[which(grepl("soares", process_survey$PID_name))] = "madelinesoares"

process_survey$PID_name[which(grepl("mardini", process_survey$PID_name))] = "mardinimardini"

process_survey$PID_name[which(grepl("nathanta", process_survey$PID_name))] = "nathanhoaita"
# cannot find mckennaanello

process_survey$PID_name[which(grepl("fisher", process_survey$PID_name))] = "nicholasfisher"

process_survey$PID_name[which(grepl("stephanie", process_survey$PID_name))] = "stephanievaladezdiosdado"

process_survey$PID_name[which(grepl("xiangjie", process_survey$PID_name))] = "xiangjie(fiona)liu"

process_survey$PID_name[which(grepl("schneider", process_survey$PID_name))] = "timothyschneider"

process_survey$PID_name[which(grepl("yifan,liu", process_survey$PID_name))] = "yifanliu"

process_survey$PID_name[which(grepl("anello", process_survey$PID_name))] = "mckennaanello"

process_survey$PID_name[which(grepl("myname", process_survey$PID_name))] = "sophianguyen"
process_survey$PID_name[which(grepl("vanessam.coronelzapata", process_survey$PID_name))] = "vanessacoronelzapata"

process_survey$PID_name[which(grepl("nayeli", process_survey$PID_name))] = "nayelilopezrivera"
process_survey$PID_name[which(grepl("britany", process_survey$PID_name))] = "britanygutierrezleon"
performance_yes_survey_no= setdiff(performance_baseline$L,process_survey$PID_name)
# cannot find "chenlin"     
names(process_survey)[names(process_survey) == "PID_name"] = "Participant"

only_in_survey = setdiff(process_survey$Participant,performance_baseline$L )
#  [1] "pleasetypeyourfullname(first&last),andmakesureit'saccuratesincewe'llneedittomatchwiththegameresult.\n\n\ntheinformationinthisstudywillbeusedonlyforresearchpurposesandinwaysthatwillnotrevealwhoyouare.yournamewilllaterbereplacedbyarandomlygeneratedidduringthedataanalysisofthestudy"
#  [2] "{\"importid\":\"qid3_text\"}"                                                                                                                                                                                                                                                           
#  [3] "jennifercastaneda"                                                                                                                                                                                                                                                                      
#  [4] "weijouhuang"                                                                                                                                                                                                                                                                            
#  [5] "honganhnguyen"                                                                                                                                                                                                                                                                          
#  [6] "diannalopez"                                                                                                                                                                                                                                                                            
#  [7] "yasminelopez"                                                                                                                                                                                                                                                                           
#  [8] "benjaminhadler"                                                                                                                                                                                                                                                                         
#  [9] "natalievarelamares"                                                                                                                                                                                                                                                                     
# [10] "victoriamoralesvargas"                                                                                                                                                                                                                                                                  
# [11] "ershuanglu"                                                                                                                                                                                                                                                                             
# [12] "tianlijiang"                                                                                                                                                                                                                                                                            
# [13] "jessicaju" 

survey_for_combine = process_survey %>% 
  select(TakeItSerious_Game_1:Participant)

# From qualitative feedback "I think the study was actually very fun and it helped me learn a new way to recall memories using my hand placements."  "It was a very interesting study and I got a chance to learn a good strategy for memorizing." 

final_participants = performance_baseline_talk %>%
  filter(!Participant %in% not_serious_id) %>%
  na.omit %>% 
  pull(Participant)

sample_size = length(unique(final_participants)) # 118

```

```{r word vs utterance, include=FALSE}
# thinking about how to connect word with utterance
subjective_1 = process_survey %>%
  select(Participant, PS_Lkrt_rati_1_1:language_PS1) %>%
  mutate(trial = 3)

names(subjective_1) = c("Participant", "PS_Lkrt_rati", "PS_Lkt_conf", "PS_pcg_rati", "PS_talk_pcg_conf", "comfortable_PS", "Content_naming", "Content_prasing", "Content_criticize", "language", "trial")

subjective_2 = process_survey %>%
  select(Participant, PS_Lkrt_rati_2_1:language_PS2) %>%
  mutate(trial = 4)

names(subjective_2) = c("Participant", "PS_Lkrt_rati", "PS_Lkt_conf", "PS_pcg_rati", "PS_talk_pcg_conf", "comfortable_PS", "Content_naming", "Content_prasing", "Content_criticize", "language", "trial")

subjective = rbind(subjective_1, subjective_2)

performance_baseline_talk_time_survey = left_join(performance_baseline_talk_time, survey_for_combine, by = "Participant") %>%
  left_join(subjective, by = c("Participant", "trial")) %>%
  filter(Participant %in% final_participants) 

write_csv(performance_baseline_talk_time_survey, "/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/NNPP_cleaned_compiled.csv")

recoded_full_df = performance_baseline_talk_time_survey %>%
  mutate_at(vars(TakeItSerious_Game_1, TakeItSerious_Survey_1, SSS_family, SSS_self),
            ~dplyr::recode(.,
                    "I did not follow the instructions of the game and instead tried to finish the game as quickly as possible.\n1" = "1", 
                    "I followed the instructions of the game, and played the game to the best of my ability\n4" = "4", 
                    "I did not read those questions carefully, and instead, I answered them as quickly as possible.\n1" ="1", 
                    "I read the questions carefully, and answered honestly to the best of my ability\n4" = "4",
                    "1 (the worst off)"= "1",
                    "10 (the best off)" = "10", )) %>%
  mutate_at(vars(PS_Lkrt_rati, PS_Lkt_conf, PS_pcg_rati, PS_pcg_rati, Age, TakeItSerious_Game_1, TakeItSerious_Survey_1, PS_talk_pcg_conf,	comfortable_PS, Content_naming, Content_prasing, Content_criticize, SSS_self, SSS_family), 
            ~ as.numeric(.))

write_csv(recoded_full_df, "/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/recoded_full_df.csv")
```

```{r corrplot function and corrplot, echo=FALSE}

cor.test(recoded_full_df %>% pull(word_min), recoded_full_df %>% pull(PS_Lkrt_rati))
#  	Pearson's product-moment correlation
# 
# data:  recoded_full_df %>% pull(word_min) and recoded_full_df %>% pull(PS_Lkrt_rati)
# t = 5.4251, df = 229, p-value = 1.47e-07
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.2178837 0.4470736
# sample estimates:
#       cor 
# 0.3374704 


cor.test(recoded_full_df %>% pull(word_min), recoded_full_df %>% pull(PS_pcg_rati))
# 	Pearson's product-moment correlation
# 
# data:  recoded_full_df %>% pull(word_min) and recoded_full_df %>% pull(PS_pcg_rati)
# t = 5.8588, df = 229, p-value = 1.61e-08
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.2433085 0.4683006
# sample estimates:
#       cor 
# 0.3610472 

cor.test(recoded_full_df %>% pull(utterance_min), recoded_full_df %>% pull(PS_Lkrt_rati))
# 	Pearson's product-moment correlation
# 
# data:  recoded_full_df %>% pull(utterance_min) and recoded_full_df %>% pull(PS_Lkrt_rati)
# t = 6.7518, df = 229, p-value = 1.188e-10
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.2938318 0.5097253
# sample estimates:
#       cor 
# 0.4074558  

cor.test(recoded_full_df %>% pull(utterance_min), recoded_full_df %>% pull(PS_pcg_rati))
# 	Pearson's product-moment correlation
# 
# data:  recoded_full_df %>% pull(utterance_min) and recoded_full_df %>% pull(PS_pcg_rati)
# t = 6.4597, df = 229, p-value = 6.223e-10
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.2775846 0.4965123
# sample estimates:
#       cor 
# 0.3925955 


cor.test(recoded_full_df %>% pull(utterance_count), recoded_full_df %>% pull(PS_pcg_rati))
# 	Pearson's product-moment correlation
# 
# data:  recoded_full_df %>% pull(utterance_count) and recoded_full_df %>% pull(PS_pcg_rati)
# t = 7.0711, df = 233, p-value = 1.777e-11
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.3089828 0.5203185
# sample estimates:
#       cor 
# 0.4203347  
cor.test(recoded_full_df %>% pull(word_count), recoded_full_df %>% pull(PS_pcg_rati))
# 	Pearson's product-moment correlation
# 
# data:  recoded_full_df %>% pull(word_count) and recoded_full_df %>% pull(PS_pcg_rati)
# t = 4.7345, df = 233, p-value = 3.814e-06
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.1749025 0.4087215
# sample estimates:
#       cor 
# 0.2962441

correlation_zeroOrder_plot = function(df, original_col_list, renamed_col_list) {
    # corr.matrix -- correlation table and heatmap
    corelation_matrix = as.data.frame(df[, original_col_list])

    # corelation_matrix[is.na(corelation_matrix)] <- 0
    colnames(corelation_matrix) = renamed_col_list

    corelation_matrix_cor <- round(cor(corelation_matrix, use = "pairwise.complete.obs"),
        3)
    res1 <- cor.mtest(corelation_matrix_cor, conf.level = 0.95)

    corrplot(corelation_matrix_cor, p.mat = res1$p, method = "color", type = "upper",
        sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.9, tl.cex = 0.9,
        insig = "label_sig", pch.col = "white")

    # corelation_matrix_plot =
    # corrplot::corrplot.mixed(corelation_matrix_cor,lower.col =
    # 'black', number.cex = .7,p.mat = res1$p, upper = 'color',
    # sig.level = c(.001, .01, .05), pch.cex = .9, tl.cex = 0.5,
    # insig = 'label_sig', pch.col = 'white')
}

names(recoded_full_df)
#  [1] "Participant"                  "trial"                       
#  [3] "word_count"                   "utterance_count"             
#  [5] "performance_difference" "baseline"                   
#  [7] "time"                         "word_min"                    
#  [9] "utterance_min"                "TakeItSerious_Game_1"        
# [11] "TakeItSerious_Survey_1"       "Age"                         
# [13] "Gender"                       "Gender_3_TEXT"               
# [15] "EthnoRacial"                  "ETHNORACIAL_mixed"           
# [17] "Country_born"                 "Country_growUp"              
# [19] "AgeToUS"                      "COLLEGE STANDING"            
# [21] "TRANSFER STUDENT"             "SSS_self"                    
# [23] "SSS_family"                   "PS_Lkrt_rati"                
# [25] "PS_Lkt_conf"                  "PS_pcg_rati"                 
# [27] "PS_talk_pcg_conf"             "comfortable_PS"              
# [29] "Content_naming"               "Content_prasing"             
# [31] "Content_criticize"            "language"   

correlation_zeroOrder_plot(
  df = recoded_full_df, 
  original_col_list = c("word_count", "word_min", "utterance_count", "utterance_min", "performance_difference", "performance_ratio",  "baseline_difference", "baseline_ratio", "time", "PS_Lkrt_rati", "PS_Lkt_conf", "PS_pcg_rati", "PS_talk_pcg_conf", "comfortable_PS"), 
  renamed_col_list = c("word_count", "word_min", "utterance_count", "utterance_min", "performance_difference", "performance_ratio", "baseline_difference", "baseline_ratio", "time",  "PS_Lkrt_rati", "PS_Lkt_conf", "PS_pcg_rati", "PS_talk_pcg_conf", "comfortable")) ## there is no correlation between performance_difference and the extent to which they talk out loud during the game. 
```

```{r SURVEY clean data and recode, echo=FALSE}

Likert_scale_viz = function(df, original_col, renamed_col, input_level){
  df[[original_col]] = factor(df[[original_col]], levels = input_level, ordered = TRUE)
  names(df)[names(df) == original_col] = renamed_col
result = data.frame(df[,which(colnames(df) == renamed_col)]) 
 names(result)= gsub("\\."," ", names(result))
  plot(likert(result), legend.position = "right")
}


original_col = c("TakeItSerious_Survey_1")
renamed_col = c("How seriously did you answer the questions after the games")
df = recoded_full_df
input_level = c("1", "2", "3", "4" )

Likert_scale_plot = (Likert_scale_viz(df, original_col, renamed_col, input_level))

### verbal content questions
recoded_full_df$Content_prasing = as.character(recoded_full_df$Content_prasing)
recoded_full_df$Content_criticize = as.character(recoded_full_df$Content_criticize)
recoded_full_df$Content_naming = as.character(recoded_full_df$Content_naming)
verbal_content  <- recoded_full_df  %>% 
  select(Content_naming, Content_prasing, Content_criticize) %>%
  rename("Naming the object that you saw" = Content_naming,
          "Saying positive things to yourself (e.g. praising yourself)" = Content_prasing,
          "Saying negative things to yourself (e.g. criticizing yourself)" = Content_criticize) %>%
  mutate_if(is.character, function(x){factor(x, levels =c("1", "2", "3", "4", "5","6", "7"))}) 

verbal_content = data.frame(verbal_content)
 names(verbal_content)= gsub("\\."," ", names(verbal_content))

## Not Grouped
# plot(likert(dh)) # basic not grouped
Likert_scale_multipleQs = (plot(likert(verbal_content), legend.position="right"))

### density plots
# PS_pcg_rati 1 & 2
density_pcg = (ggplot(data = recoded_full_df, aes(x = PS_pcg_rati)) + geom_density() +
  geom_vline(aes(xintercept = median(recoded_full_df$PS_pcg_rati, na.rm = T)), 
             linetype = "dashed", size = 0.6, color = "#d8b365") +labs(title = "Density and median of private speech percentage rating", x = "what percentage of the time were you talking out loud to yourself \n(as opposed to being silent inside your head)") + theme_classic())
```

```{r SURVEY summary might delete later, echo=FALSE}
describe(recoded_full_df) # but it also has categorical data
```

```{r EDA, include=FALSE}
recoded_full_df$Content_criticize = as.numeric(recoded_full_df$Content_criticize)
recoded_full_df$Content_naming = as.numeric(recoded_full_df$Content_naming)
recoded_full_df$Content_prasing = as.numeric(recoded_full_df$Content_prasing)

tableOne <- CreateTableOne(vars = colnames(recoded_full_df), 
                           strata = c("Gender"), 
                           data = recoded_full_df %>% filter(!Gender == "Non-binary"))
  #                                         Stratified by Gender
  #                                          Man           Women         p      test
  # n                                           54           158                    
  # word_count (mean (SD))                   62.81 (47.04) 58.34 (41.72)  0.513     
  # utterance_count (mean (SD))              30.56 (10.63) 27.90 (12.36)  0.160     
  # baseline (mean (SD))                     6.35 (2.65)   5.44 (2.94)   0.044     
  # performance_difference (mean (SD))  5.89 (3.98)   5.90 (3.68)   0.982     
  # time (mean (SD))                         62.56 (18.31) 70.88 (29.65)  0.054     
  # word_min (mean (SD))                     57.88 (31.50) 52.96 (37.10)  0.386     
  # utterance_min (mean (SD))                30.70 (11.59) 25.87 (11.32)  0.008     
  # TakeItSerious_Game_1 (mean (SD))          3.85 (0.36)   3.82 (0.44)   0.664     
  # TakeItSerious_Survey_1 (mean (SD))        3.96 (0.19)   3.96 (0.19)   0.975     
  # PS_Lkrt_rati (mean (SD))                  5.59 (1.12)   5.32 (1.36)   0.190     
  # PS_Lkt_conf (mean (SD))                   6.33 (0.97)   6.18 (1.02)   0.327     
  # PS_pcg_rati (mean (SD))                  76.63 (19.08) 75.18 (22.69)  0.674     
  # PS_talk_pcg_conf (mean (SD))              6.07 (1.04)   6.05 (0.94)   0.878     
  # comfortable_PS (mean (SD))                5.50 (1.60)   4.74 (1.76)   0.006     
  # Content_naming (mean (SD))                6.46 (1.06)   6.11 (1.38)   0.088     
  # Content_prasing (mean (SD))               1.77 (1.10)   2.56 (1.86)   0.028     
  # Content_criticize (mean (SD))             2.00 (1.51)   2.03 (1.26)   0.916

print(
  tableOne,
  nonnormal = c("word_count","word_min", "utterance_count", "baseline_difference", "time", "performance_difference"),
  showAllLevels = TRUE)

setwd("/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data")
recoded_full_df %>%
    create_report(
        output_file = "EFA_NNPP_Report"
    )
```

```{r scaling data, include=FALSE}
all_content_full_df = recoded_full_df %>%
  mutate_at(vars(Content_naming,Content_prasing, Content_criticize), as.numeric) %>%
  mutate(all_content = ambiguousunclear + naming+ reaction+recall +recognition + negativeaffect+ positiveaffect+ location+ multipurpose+ strategy+ uninformativeattention + loop + describing + irrelevant + other) %>%
  mutate(ambiguous_pcg = ambiguousunclear/all_content,
         naming_pcg = naming/all_content,
         reaction_pcg = reaction/all_content,
         recall_pcg = recall/all_content,
         recognition_pcg = recognition/all_content,
         negativeaffect_pcg = negativeaffect/all_content,
         positiveaffect_pcg = positiveaffect/all_content,
         location_pcg = location/all_content,
         multipurpose_pcg = multipurpose/all_content,
         strategy_pcg = strategy/all_content,
         uninformative_pcg = uninformativeattention/all_content,
         loop_pcg = loop/all_content,
         describing_pcg = describing/all_content,
         irrelevant_pcg = irrelevant/all_content) %>%
  mutate(ambiguous_rate = ambiguousunclear/time,
         naming_rate = naming/time,
         reaction_rate = reaction/time,
         recall_rate = recall/time,
         recognition_rate = recognition/time,
         negativeaffect_rate = negativeaffect/time,
         positiveaffect_rate = positiveaffect/time,
         location_rate = location/time,
         multipurpose_rate = multipurpose/time,
         strategy_rate = strategy/time,
         uninformative_rate = uninformativeattention/time,
         loop_rate = loop/time, 
         describing_rate = describing/time,
         irrelevant_rate = irrelevant/time)

all_content_full_long = all_content_full_df %>%
  select(Participant, 
         ambiguous_pcg, 
         naming_pcg,
         reaction_pcg,
         recall_pcg,
         recognition_pcg,
         negativeaffect_pcg,
         positiveaffect_pcg,
         location_pcg,
         multipurpose_pcg,
         strategy_pcg,
         uninformative_pcg,
         loop_pcg,
         describing_pcg,
         irrelevant_pcg) %>%
  pivot_longer(cols = c("ambiguous_pcg", "naming_pcg", "reaction_pcg", "recall_pcg", "recognition_pcg", "negativeaffect_pcg", "positiveaffect_pcg", "location_pcg","multipurpose_pcg", "strategy_pcg", "uninformative_pcg", "loop_pcg", "describing_pcg","irrelevant_pcg"), names_to = "content", values_to = "percentage") 

scaled_df = all_content_full_df %>%
  scale() %>%
  data.frame()

unpopular_yes = recoded_full_df %>% mutate(reaction_yes = ifelse(reaction > 0, "1", "0"), 
         recall_yes = ifelse(recall > 0, "1", "0"), 
         recognition_yes = ifelse(recognition > 0, "1", "0"),
         negativeaffect_yes = ifelse(negativeaffect >0, "1", "0"),
         positiveaffect_yes = ifelse(positiveaffect >0, "1", "0"),
         location_yes = ifelse(location > 0, "1", "0"),
         multipurpose_yes = ifelse(multipurpose >0, "1", "0"),
         strategy_yes = ifelse(strategy > 0, "1", "0"),
         uninformative_yes = ifelse(uninformativeattention > 0, "1", "0"),
         loop_yes = ifelse(loop >0, "1", "0"),
         describing_yes = ifelse(describing >0, "1", "0"), 
         ambiguous_yes = ifelse(ambiguousunclear >0, "1", "0"))

scaled_df = cbind(scaled_df,unpopular_yes)


scaled_full_df = cbind(recoded_full_df %>%
  select(Participant, trial, TakeItSerious_Game_1:SSS_family, language), scaled_df) 

write_csv(scaled_full_df, "/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data/NNPP_merged_data/scaled_full_df.csv")

setwd("/Users/guoxinqieve/Library/CloudStorage/OneDrive-UCSanDiego/Dissertation/NNPP (NO manipulation)/NNPP_data")
scaled_full_df %>%
    create_report(
        output_file = "scaled_NNPP_Report"
    )
```

```{r analysis, echo=FALSE}
full_model_word_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio * word_count + (1|Participant))
lesion_model_word_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio + word_count + (1|Participant))

tab_model(full_model_word_ratio,lesion_model_word_ratio, p.val = "kr" )

full_model_word_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference * word_count + (1|Participant))
lesion_model_word_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + word_count + (1|Participant))

tab_model(full_model_word_diff,lesion_model_word_diff, p.val = "kr" )

plot_model(full_model_word_ratio, type = "pred", terms = c("word_count", "baseline_ratio"))
plot_model(full_model_word_diff, type = "pred", terms = c("word_count", "baseline_difference"))

# Data: performance_difference_baseline_talk_time_survey
# Models:
# lesion_model_word: performance_difference ~ baseline + word_count + (1 | Participant)
# full_model_word: performance_difference ~ baseline * word_count + (1 | Participant)
#                   npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
# lesion_model_word    5 1242.0 1259.3 -616.02   1232.0                     
# full_model_word      6 1243.7 1264.4 -615.84   1231.7 0.3517  1     0.5531

full_model_utterance_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference * utterance_count + (1|Participant))
lesion_model_utterance_diff = lmer(data = scaled_full_df, performance_difference   ~ baseline_difference + utterance_count + (1|Participant))
tab_model(full_model_utterance_diff,lesion_model_utterance_diff, p.val = "kr" )
plot_model(full_model_utterance_diff, type = "pred", terms = c("utterance_count", "baseline_difference"))

# Data: scaled_full_df
# Models:
# lesion_model_utterance: performance_difference ~ baseline + utterance_count + (1 | Participant)
# full_model_utterance: performance_difference ~ baseline * utterance_count + (1 | Participant)
#                        npar    AIC    BIC  logLik deviance Chisq Df Pr(>Chisq)
# lesion_model_utterance    5 1244.2 1261.4 -617.08   1234.2                    
# full_model_utterance      6 1246.2 1266.9 -617.08   1234.2 0.008  1     0.9286

plot_model(full_model_utterance_diff, type = "pred", terms = c("utterance_count", "baseline_difference"))


m1_utterance_min_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference * utterance_min + (1|Participant))
m0_utterance_min_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + utterance_min + (1|Participant))

tab_model(m1_utterance_min_diff,m0_utterance_min_diff, p.val = "kr" )
plot_model(m1_utterance_min_diff, type = "pred", terms = c("utterance_min", "baseline_difference"))

full_model_word_min_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference * word_min + (1|Participant))
lesion_word_min_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + word_min + (1|Participant))

tab_model(full_model_word_min_diff,lesion_word_min_diff, p.val = "kr" )

plot_model(full_model_word_min_diff, type = "pred", terms = c("word_min", "baseline_difference"))
##
full_model_word_min_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio * word_min + (1|Participant))
lesion_word_min_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio + word_min + (1|Participant))

tab_model(full_model_word_min_ratio,lesion_word_min_ratio, p.val = "kr" )

plot_model(full_model_word_min_diff, type = "pred", terms = c("word_min", "baseline_difference"))

full_model_utterance_min_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio * utterance_min + (1|Participant))
lesion_utterance_min_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio+ utterance_min + (1|Participant))

plot_model(full_model_utterance_min_ratio, type = "pred", terms = c("utterance_min", "baseline_ratio"), title = "Performance as a function of\nprivate speech usage and baseline", axis.title = c("Standardized utterances per minute", "Standardized Performanace Ratio"), colors = c("#FFBF00","#808080","#0A7029")) + theme_classic() + aes(linetype= group)

#### the graph with baseline regressed out
plot_model(full_model_utterance_min_ratio, type = "pred", terms = c("utterance_min"), title = "Marginal effect of private speech usage on performance\n- baseline regressed out", axis.title = c("Standardized utterances per minute", "Standardized Performanace Ratio")) + theme_classic()

full_model_utterance_count_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio * utterance_count + (1|Participant))
lesion_utterance_count_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio+ utterance_count + (1|Participant))

plot_model(full_model_utterance_count_ratio, type = "pred", terms = c("utterance_count", "baseline_ratio"), title = "Performance as a function of\nprivate speech usage and baseline", axis.title = c("Standardized utterances", "Standardized Performanace Ratio"), colors = c("#FFBF00","#808080","#0A7029")) + theme_classic() + aes(linetype= group)


# note to self this plot in EF_Rate_control_DifferentDF_Plot from PrivateSpeech.Rmd is the phase 1 data.
b = read_csv("/Users/guoxinqieve/Applications/OneDrive - UC San Diego/less old files/concentration_Private_Speech/phase_1_interaction.csv")
b$EF_turns = b$EF/2
b$DF_turns = b$DF/2
interaction_PS_Flips = lm(data = b, EF_turns ~ DF_turns * RATE)
summary(interaction_PS_Flips)
EF_Rate_control_DifferentDF_Plot = plot_model(interaction_PS_Flips, type = "pred", terms = c("RATE", "DF_turns"), title = "Phase 1: Performance as a function of\nprivate speech usage and baseline", axis.title = c("Utterances per minute", "Actual turns used"), colors = c("#FFBF00","#808080","#0A7029")) + theme_classic() + aes(linetype= group) + scale_y_continuous( limits = c(0, 65))
car::Anova(lm(EF_turns ~ DF_turns * RATE, data=b, contrasts=list(topic=contr.sum, sys=contr.sum), type=3))
car::Anova(lm(ET ~ DT * RATE, data=b, contrasts=list(topic=contr.sum, sys=contr.sum), type=3))
cor.test(b$EF, b$ET)
# 	Pearson's product-moment correlation
# 
# data:  b$EF and b$ET
# t = 1.5283, df = 55, p-value = 0.1322
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  -0.06198868  0.43930266
# sample estimates:
#       cor 
# 0.2018391 
cor.test(b$DF, b$DT)
# 
# 	Pearson's product-moment correlation
# 
# data:  b$DF and b$DT
# t = 3.0395, df = 55, p-value = 0.003623
# alternative hypothesis: true correlation is not equal to 0
# 95 percent confidence interval:
#  0.1316723 0.5822605
# sample estimates:
#       cor 
# 0.3792288 

interaction_PS_Time = lm(data = b, ET ~ DT * RATE)

ET_Rate_control_DifferentDT_Plot = plot_model(interaction_PS_Time, type = "pred", terms = c("RATE", "DT"), title = "Phase 1: Performance as a function of\nprivate speech usage and baseline", axis.title = c("Utterances per minute", "Total time used"), colors = c("#FFBF00","#808080","#0A7029")) + theme_classic() + aes(linetype= group) + scale_y_continuous(limits = c(0, 200))

tab_model(full_model_utterance_min_ratio, lesion_utterance_min_ratio, p.val = "kr" )


full_model_word_min_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio * word_min + (1|Participant))
lesion_model_word_min_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio + word_min + (1|Participant))

tab_model(full_model_word_min_ratio,lesion_model_word_min_ratio,  p.val = "kr" )

### looking at main effect 
no_word_min = lmer(data = scaled_full_df %>% filter(!is.na(word_min)), performance_difference ~ baseline_difference + (1|Participant))
lesion_word_min = lmer(data = scaled_full_df %>% filter(!is.na(word_min)), performance_difference ~ baseline_difference + word_min + (1|Participant))
tab_model(no_word_min, lesion_word_min, p.val = "kr")
plot_model(lesion_word_min, type = "pred", terms = c("word_min"))


no_utterance_min = lmer(data = scaled_full_df %>% filter(!is.na(utterance_min)), performance_difference ~ baseline_difference + (1|Participant))
lesion_utterance_min = lmer(data = scaled_full_df %>% filter(!is.na(utterance_min)), performance_difference ~ baseline_difference + utterance_min + (1|Participant))
tab_model(no_utterance_min, lesion_utterance_min, p.val = "kr")
plot_model(lesion_utterance_min, type = "pred", terms = c("utterance_min"))


no_word = lmer(data = scaled_full_df %>% filter(!is.na(word_count)), performance_difference ~ baseline_difference + (1|Participant))
lesion_word = lmer(data = scaled_full_df %>% filter(!is.na(word_count)), performance_difference ~ baseline_difference + word_count + (1|Participant))
tab_model(no_word, lesion_word, p.val = "kr")

no_utterance = lmer(data = scaled_full_df %>% filter(!is.na(utterance_count)), performance_difference ~ baseline_difference + (1|Participant))
lesion_utterance = lmer(data = scaled_full_df %>% filter(!is.na(utterance_count)), performance_difference ~ baseline_difference + utterance_count + (1|Participant))

tab_model(no_utterance, lesion_utterance, p.val = "kr")
```

```{r comfortableness, echo=FALSE}
no_comfortableness = lmer(data = scaled_full_df %>% filter(!is.na(comfortable_PS)), performance_difference ~ baseline_difference + (1|Participant))
comfortableness = lmer(data = scaled_full_df %>% filter(!is.na(comfortable_PS)), performance_difference ~ baseline_difference + comfortable_PS + (1|Participant))
comfortableness_interaction = lmer(data = scaled_full_df %>% filter(!is.na(comfortable_PS)), performance_difference ~ baseline_difference * comfortable_PS + (1|Participant))

tab_model(comfortableness, comfortableness_interaction, p.val = "kr")
plot_model(comfortableness, type = "pred")


utter_rate_comfort = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + utterance_min +comfortable_PS + (1|Participant))
tab_model( utter_rate_comfort, p.val = "kr")

word_rate_comfort = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + word_min +comfortable_PS + (1|Participant))
tab_model( word_rate_comfort, p.val = "kr")

##### ratio
no_comfortableness = lmer(data = scaled_full_df %>% filter(!is.na(comfortable_PS)), performance_ratio ~ baseline_ratio + (1|Participant))
comfortableness = lmer(data = scaled_full_df %>% filter(!is.na(comfortable_PS)), performance_ratio ~ baseline_ratio + comfortable_PS + (1|Participant))
comfortableness_interaction = lmer(data = scaled_full_df %>% filter(!is.na(comfortable_PS)), performance_ratio ~ baseline_ratio * comfortable_PS + (1|Participant))

tab_model(comfortableness, comfortableness_interaction, p.val = "kr")
plot_model(comfortableness, type = "pred")


comfortableness_utterance = lmer(data = scaled_full_df %>% filter(!is.na(comfortable_PS)), performance_ratio ~ baseline_ratio + utterance_min+ comfortable_PS + (1|Participant))

comfortableness_utterance_interaction = lmer(data = scaled_full_df %>% filter(!is.na(comfortable_PS)), performance_ratio ~ baseline_ratio + utterance_min*comfortable_PS + (1|Participant))

tab_model(comfortableness_utterance, p.val = "kr")
tab_model(comfortableness_utterance_interaction, p.val = "kr")

rmcorr(
  participant = Participant,
  measure1 = comfortable_PS,
  measure2 = utterance_min,
  scaled_full_df,
  CI.level = 0.95,
  CIs = c("analytic", "bootstrap"),
  nreps = 100,
  bstrap.out = F
)

rmcorr(
  participant = Participant,
  measure1 = comfortable_PS,
  measure2 = baseline_ratio,
  scaled_full_df,
  CI.level = 0.95,
  CIs = c("analytic", "bootstrap"),
  nreps = 100,
  bstrap.out = F
)

rmcorr(
  participant = Participant,
  measure1 = utterance_min,
  measure2 = baseline_ratio,
  scaled_full_df,
  CI.level = 0.95,
  CIs = c("analytic", "bootstrap"),
  nreps = 100,
  bstrap.out = F
)

tab_model(lmer(data = scaled_full_df, utterance_min~ 1 + baseline_ratio + (1|Participant)), p.val = "kr")

rmcorr(
  participant = Participant,
  measure1 = utterance_min,
  measure2 = naming_pcg,
  all_content_full_df,
  CI.level = 0.95,
  CIs = c("analytic", "bootstrap"),
  nreps = 100,
  bstrap.out = F
)

tab_model(lmer(data = all_content_full_df %>% select(Participant, utterance_min, naming_pcg), utterance_min ~ naming_pcg + (1|Participant)))


```

```{r subjective, echo=FALSE}
## adding comfortableness
no_likert = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + (1|Participant))

lesion_likert = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_Lkrt_rati + (1|Participant))

interaction_likert = lmer(data = scaled_full_df, performance_difference ~ baseline_difference * PS_Lkrt_rati + (1|Participant))
tab_model(interaction_likert, lesion_likert, p.val = "kr")
tab_model(lesion_likert, p.val = "kr")

subjective_against_comfort = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_Lkrt_rati + comfortable_PS + (1|Participant))
tab_model(subjective_against_comfort, p.val = "kr")



baseline_likert_plus = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_Lkrt_rati + (1|Participant))

baseline_likert_comfort_plus = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_Lkrt_rati + comfortable_PS+ (1|Participant))


tab_model(no_likert, lesion_likert, p.val = "kr")
tab_model(lesion_likert, interaction_likert, p.val = "kr")
tab_model(baseline_likert_plus, baseline_likert_comfort_plus, p.val = "kr")

### adding for percentage
## adding comfortableness
no_pcg = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + (1|Participant))
lesion_pcg = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_pcg_rati + (1|Participant))
interaction_pcg = lmer(data = scaled_full_df, performance_difference ~ baseline_difference * PS_pcg_rati + (1|Participant))
baseline_pcg_plus = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_pcg_rati + (1|Participant))
baseline_pcg_comfort_plus = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_pcg_rati + comfortable_PS+ (1|Participant))

tab_model(no_pcg, lesion_pcg, p.val = "kr")
tab_model(lesion_pcg, interaction_pcg, p.val = "kr")
tab_model(baseline_pcg_plus, baseline_pcg_comfort_plus, p.val = "kr")


```

```{r subjective and objective, include=FALSE}
m1 = lmer(data = scaled_full_df, PS_Lkrt_rati ~ utterance_min + word_min + utterance_count + word_count + (1|Participant))
m2 = lmer(data = scaled_full_df, performance_difference ~ baseline_difference + PS_pcg_rati + comfortable_PS+ (1|Participant))
```

```{r baseline and self talk, echo=FALSE}
# are baseline and self talk related - utterance 
m1 = lmer(data = scaled_full_df %>% filter(!is.na(utterance_count), !is.na(time)), baseline_difference ~ 1+ utterance_min + (1|Participant))

m0 = lmer(data = scaled_full_df %>% filter(!is.na(utterance_count), !is.na(time)), baseline_difference ~ 1 + (1|Participant))

anova(m1,m0) # utterance_min does not predict baseline

# are baseline and self talk related - word
m1 = lmer(data = scaled_full_df %>% filter(!is.na(word_count), !is.na(time)), baseline_difference ~ 1+ word_min + (1|Participant))

m0 = lmer(data = scaled_full_df %>% filter(!is.na(word_count), !is.na(time)), baseline_difference ~ 1 + (1|Participant))

anova(m1,m0) # count_min does not predict baseline
```

```{r determining ration versus difference, include=FALSE}
# voting for ratio rather than difference because there seems to be a disadvantage for participants whose turns assuming perfect is high - more cognitive load
## according to the analyses below there is no correlation between the error they are getting and the turns they need to get 

rmcorr(
  participant = L,
  measure1 = performance_difference,
  measure2 = turn_assume_perfect,
  processing_performance,
  CI.level = 0.95,
  CIs = c("analytic", "bootstrap"),
  nreps = 100,
  bstrap.out = F
)
# Repeated measures correlation
# 
# r
# 0.01058324
# 
# degrees of freedom
# 465
# 
# p-value
# 0.8195691
# 
# 95% confidence interval
# -0.08042805 0.1014195 


rmcorr(
  participant = L,
  measure1 = performance_ratio,
  measure2 = turn_assume_perfect,
  dataset = processing_performance,
  CI.level = 0.95,
  CIs = c("analytic", "bootstrap"),
  nreps = 100,
  bstrap.out = F
)
# Repeated measures correlation
# 
# r
# -0.06591199
# 
# degrees of freedom
# 465
# 
# p-value
# 0.1549973
# 
# 95% confidence interval
# -0.1559114 0.02517277 
```

```{r which objective is closer to subjective, include = FALSE}
rmcorr(
  participant = Participant,
  measure1 = PS_Lkrt_rati,
  measure2 = utterance_min,
  scaled_full_df,
  CI.level = 0.95,
  CIs = c("analytic", "bootstrap"),
  nreps = 100,
  bstrap.out = F
)
# Repeated measures correlation
# 
# r
# 0.1866851
# 
# degrees of freedom
# 113
# 
# p-value
# 0.04574886
# 
# 95% confidence interval
# 0.002025097 0.3590332 

rmcorr(
  participant = Participant,
  measure1 = PS_Lkrt_rati,
  measure2 = utterance_count,
  scaled_full_df,
  CI.level = 0.95,
  CIs = c("analytic", "bootstrap"),
  nreps = 100,
  bstrap.out = F
)
# Repeated measures correlation
# 
# r
# -0.001509061
# 
# degrees of freedom
# 116
# 
# p-value
# 0.9870604
# 
# 95% confidence interval
# -0.1837751 0.1808573 

rmcorr(
  participant = Participant,
  measure1 = PS_Lkrt_rati,
  measure2 = word_min,
  scaled_full_df,
  CI.level = 0.95,
  CIs = c("analytic", "bootstrap"),
  nreps = 100,
  bstrap.out = F
)
# Repeated measures correlation
# 
# r
# 0.2132152
# 
# degrees of freedom
# 113
# 
# p-value
# 0.02214482
# 
# 95% confidence interval
# 0.02965332 0.382865 

rmcorr(
  participant = Participant,
  measure1 = PS_Lkrt_rati,
  measure2 = word_count,
  scaled_full_df,
  CI.level = 0.95,
  CIs = c("analytic", "bootstrap"),
  nreps = 100,
  bstrap.out = F
)
# Repeated measures correlation

# r
# 0.08955015
# 
# degrees of freedom
# 116
# 
# p-value
# 0.3348717
# 
# 95% confidence interval
# -0.09430615 0.2674994
```

```{r content, echo=FALSE}
# content analysis
full_content_word_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio + ambiguous_rate+
         naming_rate +
         reaction_rate +
         recall_rate+
         recognition_rate +
         negativeaffect_rate +
         positiveaffect_rate+
         location_rate +
         multipurpose_rate +
         strategy_rate +
         uninformative_rate +
         loop_rate +
         describing_rate +
         irrelevant_rate + (1|Participant))

full_content_word_ratio_comfort = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio + ambiguous_rate+
         naming_rate +
         reaction_rate +
         recall_rate+
         recognition_rate +
         negativeaffect_rate +
         positiveaffect_rate+
         location_rate +
         multipurpose_rate +
         strategy_rate +
         uninformative_rate +
         loop_rate +
         describing_rate +
         irrelevant_rate + comfortable_PS+ (1|Participant))

tab_model(full_content_word_ratio_comfort,p.val = "kr" )


full_content_word_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference +ambiguousunclear +naming+reaction +recall+recognition+negativeaffect+positiveaffect+location +multipurpose + strategy+ uninformativeattention+ loop +describing+irrelevant+ (1|Participant))

tab_model(full_content_word_diff,p.val = "kr" )
# ### content analysis but with percentages-- performance difference
# full_content_pcg_word_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference +ambiguous_pcg +naming_pcg+reaction_pcg +recall_pcg+recognition_pcg+negativeaffect_pcg+positiveaffect_pcg+location_pcg +multipurpose_pcg + strategy_pcg+ uninformative_pcg+ loop_pcg +describing_pcg+irrelevant_pcg+ (1|Participant))
# tab_model(full_content_pcg_word_diff,p.val = "kr" )
# 
# ### content analysis but with percentages -- performance ratio
# full_content_pcg_word_ratio = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio +ambiguous_pcg +naming_pcg+reaction_pcg +recall_pcg+recognition_pcg+negativeaffect_pcg+positiveaffect_pcg+location_pcg +multipurpose_pcg + strategy_pcg+ uninformative_pcg+ loop_pcg +describing_pcg+irrelevant_pcg+ (1|Participant))
# 
# tab_model(full_content_pcg_word_ratio,p.val = "kr" )
```

```{r graphs, include=FALSE}
ggplot(data = recoded_full_df, aes(x = turn_assume_perfect)) +
  geom_histogram(color="black", fill="white") +
  theme_classic() +
  labs(title = "Number of turns needed when no errors were made\nvaries from trial to trial (due to luck)", x = "Turns assume no memory error", y = "number of trials")

ggplot(data = recoded_full_df, aes(x = comfortable_PS)) +
  geom_histogram(color="black", fill="white") +
  theme_classic() +
  labs(title = "The vast majority of the participants are\ncomfortable with talking out-loud", x = "Comfortableness with Talking Out-loud during the Game", y = "Count") + scale_x_continuous( breaks = c(0, 8, 1))


recoded_full_df$Gender[recoded_full_df$Gender == "Man"] = "Men"
  
ggplot(data = recoded_full_df, aes(x = performance_ratio)) +
  geom_histogram(color="black", fill="white") +
  theme_classic() +
  labs(title = "Distribution of Performance Ratio", x = "Performance ratio", y = "Number of Trials") +
  scale_x_continuous(breaks = seq(0.5, 2.5, by = 0.5)) +
  geom_vline(data=mu, aes(xintercept=grp.mean, color=Gender),
             linetype="dashed")+
  theme(legend.position="top")



library(plyr)
mu <- ddply(recoded_full_df %>% filter(Gender == "Man" | Gender == "Women"), "Gender", summarise, grp.mean=mean(performance_ratio, na.rm = T))
head(mu)

mu <- ddply(recoded_full_df %>% filter(Gender == "Man" | Gender == "Women"), "Gender", summarise, grp.mean=mean(baseline_ratio, na.rm = T))
head(mu)

summary <- all_content_full_long %>%
   na.omit %>%
    group_by(content) %>%
    dplyr::summarise(mean = mean(percentage, na.rm = T), se = sd(percentage, na.rm = T) / length(!is.na(percentage)))

ggplot(data = summary, aes(x = content, y = mean, fill = content)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = mean - se, ymax = mean+se),
                width = 0.2,
                position = position_dodge(0.9)) +
  theme_classic()

  
```

```{r group comparison, include=FALSE}
# there 
if_condition_matters = processing_performance %>%
  mutate(condition = ifelse(trial >= 3, "private_speech", "neutral"))

if_condition_matters_model = lmer(data = if_condition_matters, performance_ratio ~  1 + condition + (1|L))
if_condition_matters_null = lmer(data = if_condition_matters, performance_ratio ~  1 + (1|L))
anova(if_condition_matters_null, if_condition_matters_model)

tab_model(if_condition_matters_model, p.val = "kr")

```

```{r regression for unpopular categrories, include=FALSE}
# 
# adding variables that correspond to yes/no to the unpopular variables
content_added_zero_or_not = lmer(data = scaled_full_df, performance_ratio ~ baseline_ratio + 
       ambiguous_rate+ ambiguous_yes +
         naming_rate +
         reaction_rate + reaction_yes+
         recall_rate+recall_yes+
         recognition_rate +recognition_yes+
         negativeaffect_rate +negativeaffect_yes +
         positiveaffect_rate+positiveaffect_yes +
         location_rate +location_yes+
         multipurpose_rate +multipurpose_yes + 
         strategy_rate + strategy_yes+
         uninformative_rate +uninformative_yes +
         loop_rate +loop_yes +
         describing_rate +describing_yes +
         irrelevant_rate + (1|Participant))
tab_model(content_added_zero_or_not, p.val = "kr")
```

```{r content analysis exploratory, include=FALSE}
content_zero_or_not = lmer(data = scaled_full_df, performance_ratio~ baseline_ratio + naming_rate + ambiguous_yes+ recall_yes + reaction_yes + recognition_yes + negativeaffect_yes + positiveaffect_yes + location_yes + multipurpose_yes + strategy_yes + uninformative_yes + loop_yes + describing_yes+ (1|Participant))
tab_model(content_zero_or_not, p.val = "kr")


content_pcg_utterance_rate = lmer(data = all_content_full_df, performance_ratio~ baseline_ratio+ utterance_min+ambiguous_pcg +naming_pcg+reaction_pcg +recall_pcg+recognition_pcg+negativeaffect_pcg+positiveaffect_pcg+location_pcg +multipurpose_pcg + strategy_pcg+ uninformative_pcg+ loop_pcg +describing_pcg+irrelevant_pcg + (1|Participant))

tab_model(content_pcg_utterance_rate, p.val = "kr")

# ### content analysis but with percentages-- performance difference
# full_content_pcg_word_diff = lmer(data = scaled_full_df, performance_difference ~ baseline_difference +ambiguous_pcg +naming_pcg+reaction_pcg +recall_pcg+recognition_pcg+negativeaffect_pcg+positiveaffect_pcg+location_pcg +multipurpose_pcg + strategy_pcg+ uninformative_pcg+ loop_pcg +describing_pcg+irrelevant_pcg+ (1|Participant))
# tab_model(full_content_pcg_word_diff,p.val = "kr" )
```

```{r plotting distributions, include=FALSE}
p <- if_condition_matters %>%
  ggplot( aes(x=performance_ratio, fill=condition)) +
    geom_density(alpha=0.5)+
    scale_fill_manual(values=c("#d8b365", "#5ab4ac")) +
    theme_classic() +
    labs(fill="")

df_for_2by2_distribution = recoded_full_df %>% 
  select(Participant, utterance_min, baseline_ratio, performance_ratio, utterance_count) %>%
  group_by(Participant) %>%
  dplyr::mutate(individual_performance_average = mean(performance_ratio, na.rm = T), 
         individual_talk_average = mean(utterance_min, na.rm = T),
         individual_count_average = mean(utterance_count, na.rm = T)) %>%
  ungroup() %>%  
  dplyr::mutate(group_median = median(baseline_ratio, na.rm = T),
                good_bad = ifelse(baseline_ratio >=group_median, "bad", "good"),
                group_talk_average = mean(utterance_min, na.rm = T),
                talker_or_not = ifelse(individual_talk_average >= group_talk_average, "talker", "non_talker"),
                group_count_average = mean(utterance_min, na.rm = T),
                talker_by_count = ifelse(individual_count_average >= group_count_average, "talker_count", "non_talker_count")) %>%
  select(-utterance_min, -performance_ratio, -utterance_count) %>%
  na.omit() %>%
  distinct() %>%
  pivot_longer(cols = c("baseline_ratio", "individual_performance_average"), names_to = "condition", values_to = "performance")
  

p <- df_for_2by2_distribution %>%
  mutate_at(vars(condition),
            ~dplyr::recode(.,
                     "baseline_ratio" = "baseline", 
                     "individual_performance_average" = "ps_performance")) %>%
  ggplot( aes(x=performance, fill=condition)) +
  geom_histogram(alpha= 0.5, binwidth = 0.01) +
    scale_fill_manual(values=c("#d8b365", "#5ab4ac")) +
    theme_classic() +
    labs(fill="condition", title = "talker or not decided by utterance/min") +
    facet_grid(vars(talker_or_not), vars(good_bad)) +
  theme(strip.text.x = element_text(size = 20),
        strip.text.y = element_text(size = 20)) + 
  geom_vline(xintercept = 1.28, 
             linetype="dotted",                
             color = "blue", 
             size=1.5)
# geom_histogram(color="#e9ecef", alpha=0.5, position = 'identity', binwidth = 0.01) 

p <- df_for_2by2_distribution %>%
  mutate_at(vars(condition),
            ~dplyr::recode(.,
                     "baseline_ratio" = "baseline", 
                     "individual_performance_average" = "ps_performance")) %>%
  ggplot( aes(x=performance, fill=condition)) +
    geom_text(
    size    = 5,
    data    = ann_text,
    mapping = aes(x = 1.5, y = 6, label = "text"),
    inherit.aes=FALSE
  ) +
    # geom_density(alpha = 0.5)+
  geom_histogram(alpha= 0.5, binwidth = 0.01) +
    scale_fill_manual(values=c("#d8b365", "#5ab4ac")) +
    theme_classic() +
    labs(fill="condition", title = "talker or not decided by utterance count") +
    facet_grid(vars(talker_by_count), vars(good_bad)) +
  theme(strip.text.x = element_text(size = 20),
        strip.text.y = element_text(size = 20)) 
   # geom_text(data = ann_text,label=ann_text$label)


# bad & non-talker
t.test(df_for_2by2_distribution %>% filter(good_bad == "bad" & talker_or_not == "non_talker" & condition == "baseline_ratio") %>% pull(performance), df_for_2by2_distribution %>% filter(good_bad == "bad" & talker_or_not == "non_talker" & condition == "individual_performance_average") %>% pull(performance), paired = T)

cor.test(df_for_2by2_distribution %>% filter(good_bad == "bad" & talker_or_not == "non_talker" & condition == "baseline_ratio") %>% pull(performance), df_for_2by2_distribution %>% filter(good_bad == "bad" & talker_or_not == "non_talker" & condition == "individual_performance_average") %>% pull(performance))

# good & non-talker
t.test(df_for_2by2_distribution %>% filter(good_bad == "good" & talker_or_not == "non_talker" & condition == "baseline_ratio") %>% pull(performance), df_for_2by2_distribution %>% filter(good_bad == "good" & talker_or_not == "non_talker" & condition == "individual_performance_average") %>% pull(performance), paired = T)

cor.test(df_for_2by2_distribution %>% filter(good_bad == "good" & talker_or_not == "non_talker" & condition == "baseline_ratio") %>% pull(performance), df_for_2by2_distribution %>% filter(good_bad == "good" & talker_or_not == "non_talker" & condition == "individual_performance_average") %>% pull(performance))


# bad & talker
t.test(df_for_2by2_distribution %>% filter(good_bad == "bad" & talker_or_not == "talker" & condition == "baseline_ratio") %>% pull(performance), df_for_2by2_distribution %>% filter(good_bad == "bad" & talker_or_not == "talker" & condition == "individual_performance_average") %>% pull(performance), paired = T)

cor.test(df_for_2by2_distribution %>% filter(good_bad == "bad" & talker_or_not == "talker" & condition == "baseline_ratio") %>% pull(performance), df_for_2by2_distribution %>% filter(good_bad == "bad" & talker_or_not == "talker" & condition == "individual_performance_average") %>% pull(performance))

# good & talker
t.test(df_for_2by2_distribution %>% filter(good_bad == "good" & talker_or_not == "talker" & condition == "baseline_ratio") %>% pull(performance), df_for_2by2_distribution %>% filter(good_bad == "good" & talker_or_not == "talker" & condition == "individual_performance_average") %>% pull(performance), paired = T)

cor.test(df_for_2by2_distribution %>% filter(good_bad == "good" & talker_or_not == "talker" & condition == "baseline_ratio") %>% pull(performance), df_for_2by2_distribution %>% filter(good_bad == "good" & talker_or_not == "talker" & condition == "individual_performance_average") %>% pull(performance))


dat_text <- data.frame(
   good_bad  = c("bad", "good", "bad", "good"),
  talker_or_not = c("non_talker", "non_talker", "talker", "talker")
)

dat_text$label <- c("t(20) = 0.540, p = 0.595 \nr = 0.440, p = 0.046", 
                    "t(30) = -3.518, p = 0.001 \nr = 0.331, p = 0.067",
                    "t(36) = 3.406, p = 0.002 \nr = 0.286, p = 0.086",
                    "t(27) = -2.089, p = 0.046 \nr = 0.176, p = 0.370")

ann_text <- data.frame(good_bad = factor("bad", levels = c("bad", "good")),talker_or_not = "non_talker",lab = "t(20) = 0.540, p = 0.595") %>% 
  rbind(data.frame(good_bad = factor("good", levels = c("bad", "good")),talker_or_not = "non_talker",lab = "t(30) = -3.518, p = 0.001")) %>%
  rbind(data.frame(good_bad = factor("bad", levels = c("bad", "good")),talker_or_not = "talker",lab = "t(36) = 3.406, p = 0.002")) %>%
   rbind(data.frame(good_bad = factor("good", levels = c("bad", "good")),talker_or_not = "talker",lab = "t(27) = -2.089, p = 0.046")) 
```
